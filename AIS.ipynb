{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab312b8b",
   "metadata": {},
   "source": [
    "#### To apply the artificial immune pattern recognition to perform a task of structure damage Classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f39e1024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "#MK CODE\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import mode\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "data, labels = make_classification(n_samples=100, n_features=10, \n",
    "                                    n_informative=5, n_redundant=0, \n",
    "                                    n_clusters_per_class=1, random_state=42)\n",
    "\n",
    "# Split data\n",
    "split = int(0.8 * len(data))\n",
    "X_train, X_test = data[:split], data[split:]\n",
    "y_train, y_test = labels[:split], labels[split:]\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Select detectors\n",
    "idx = np.random.choice(len(X_train), 30, replace=False)\n",
    "detectors = X_train[idx]\n",
    "detector_labels = y_train[idx]\n",
    "\n",
    "# Predict using k-nearest (k=3)\n",
    "predictions = []\n",
    "for x in X_test:\n",
    "    dists = np.linalg.norm(detectors - x, axis=1)\n",
    "    k_idx = np.argsort(dists)[:3]\n",
    "    k_labels = detector_labels[k_idx]\n",
    "    predictions.append(mode(k_labels, keepdims=True)[0][0])\n",
    "\n",
    "# Accuracy\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(f\"Accuracy: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a81483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "'''Here‚Äôs a **line-by-line breakdown** and explanation of the code you've given, along with **why each part is used** and **alternatives** where applicable. This code is an example of a **simple K-Nearest Neighbors (KNN)-like anomaly detection or classification model** ‚Äî possibly inspired by **Artificial Immune Systems (AIS)**, which is part of **Computational Intelligence**.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Code Explanation\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import mode\n",
    "from sklearn.datasets import make_classification\n",
    "```\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "* `numpy`: Used for mathematical operations and handling arrays.\n",
    "* `StandardScaler`: Used for normalization (mean=0, std=1) of features.\n",
    "* `mode`: Finds the most common label among nearest neighbors (used in prediction).\n",
    "* `make_classification`: Generates synthetic classification data for testing.\n",
    "\n",
    "**Alternatives:**\n",
    "\n",
    "* For scaling: `MinMaxScaler` or `RobustScaler`.\n",
    "* For synthetic data: `sklearn.datasets.load_iris()` (for real-world datasets).\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "data, labels = make_classification(n_samples=100, n_features=10, \n",
    "                                    n_informative=5, n_redundant=0, \n",
    "                                    n_clusters_per_class=1, random_state=42)\n",
    "```\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "* Generates a **100-sample, 10-feature** classification dataset.\n",
    "* 5 features are informative (helpful for classification), rest are noise.\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* Quick way to generate a controlled dataset for experiments.\n",
    "\n",
    "**Alternatives:**\n",
    "\n",
    "* Load real datasets like `load_breast_cancer()` or use a CSV file.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "split = int(0.8 * len(data))\n",
    "X_train, X_test = data[:split], data[split:]\n",
    "y_train, y_test = labels[:split], labels[split:]\n",
    "```\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "* Splits the data into **80% training and 20% testing** manually.\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* Required to train detectors on training data and evaluate on test data.\n",
    "\n",
    "**Alternatives:**\n",
    "\n",
    "* Use `train_test_split()` from `sklearn.model_selection` for cleaner code.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "* Normalizes the training data and applies the same transformation to the test set.\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* KNN-based algorithms are distance-based, so **feature scaling** is essential.\n",
    "\n",
    "**Alternatives:**\n",
    "\n",
    "* `MinMaxScaler` if your data needs to be between \\[0, 1].\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "idx = np.random.choice(len(X_train), 30, replace=False)\n",
    "detectors = X_train[idx]\n",
    "detector_labels = y_train[idx]\n",
    "```\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "* Randomly selects 30 training samples as **detectors** (like memory cells in AIS).\n",
    "* `detector_labels` holds their corresponding classes.\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* Simulates an **Artificial Immune System** (AIS) model.\n",
    "* Instead of using the whole training set, it mimics **distributed detection**.\n",
    "\n",
    "**Alternatives:**\n",
    "\n",
    "* Use the entire training dataset like standard KNN.\n",
    "* Use clustering (e.g., k-means) to choose representative detectors.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "predictions = []\n",
    "for x in X_test:\n",
    "    dists = np.linalg.norm(detectors - x, axis=1)\n",
    "    k_idx = np.argsort(dists)[:3]\n",
    "    k_labels = detector_labels[k_idx]\n",
    "    predictions.append(mode(k_labels, keepdims=True)[0][0])\n",
    "```\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "* For each test sample:\n",
    "\n",
    "  * Computes **Euclidean distance** from each detector.\n",
    "  * Finds 3 nearest detectors (k=3).\n",
    "  * Takes the **most frequent label** among the 3 (majority voting).\n",
    "  * Stores it as the prediction.\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* Implements a **simple KNN** classifier using only 30 detectors (like agents in distributed systems).\n",
    "\n",
    "**Alternatives:**\n",
    "\n",
    "* Use `KNeighborsClassifier` from `sklearn`.\n",
    "* Use cosine similarity instead of Euclidean distance if data is sparse or high-dimensional.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "```\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "* Calculates the **accuracy** by comparing predicted vs actual labels.\n",
    "* Prints the result.\n",
    "\n",
    "**Why used:**\n",
    "\n",
    "* Accuracy is a common evaluation metric for classification.\n",
    "\n",
    "**Alternatives:**\n",
    "\n",
    "* Use `precision`, `recall`, `f1-score`, or `confusion_matrix` for more insight.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Why This Is Related to **Computational Intelligence** and **Distributed Computing**\n",
    "\n",
    "* **Computational Intelligence:** The model mimics **AIS (Artificial Immune System)** concepts by selecting detectors (like immune cells) and recognizing patterns.\n",
    "* **Distributed Computing:** Instead of using the whole dataset, it uses selected detectors ‚Äî which simulates distributed decision-making (like edge nodes or agents doing local processing).\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary of Alternatives\n",
    "\n",
    "| Component            | Current Used                     | Alternative(s)                                     |\n",
    "| -------------------- | -------------------------------- | -------------------------------------------------- |\n",
    "| Dataset              | `make_classification()`          | Real datasets from UCI, CSV, or `load_*()` methods |\n",
    "| Data Split           | Manual slicing                   | `train_test_split()` from sklearn                  |\n",
    "| Normalization        | `StandardScaler`                 | `MinMaxScaler`, `RobustScaler`                     |\n",
    "| Distance Metric      | Euclidean (`np.linalg.norm`)     | Cosine, Manhattan, Mahalanobis                     |\n",
    "| Classification Logic | Manual KNN logic                 | `KNeighborsClassifier()` from sklearn              |\n",
    "| Accuracy Metric      | `np.mean(predictions == y_test)` | `sklearn.metrics.classification_report()`          |\n",
    "\n",
    "---\n",
    "‚úÖ AIS (Artificial Immune System) ‚Äì Theory (Simple Explanation)\n",
    "Artificial Immune System (AIS) is a type of Computational Intelligence technique inspired by the biological immune system. It is mainly used for pattern recognition, anomaly detection, classification, and optimization problems.\n",
    "\n",
    "üìò Core Concepts of AIS\n",
    "Concept\tExplanation\n",
    "Immune System Inspiration\tMimics how the human immune system detects and responds to foreign pathogens.\n",
    "Detectors / Antibodies\tRepresent models or vectors that recognize patterns (normal or abnormal).\n",
    "Antigens\tRepresent incoming data patterns to be classified or checked for anomalies.\n",
    "Affinity\tMeasures similarity between a detector and an antigen (e.g., Euclidean distance).\n",
    "Clonal Selection\tHigh-affinity detectors are cloned and mutated to improve detection (learning process).\n",
    "Negative Selection\tDetectors that recognize \"self\" data are eliminated to reduce false alarms.\n",
    "Memory Cells\tBest detectors are stored as memory for faster recognition later.\n",
    "\n",
    "üìö Types of AIS Models\n",
    "Model\tUse Case\n",
    "Negative Selection Algorithm (NSA)\tAnomaly detection ‚Äì detects data that is different from \"normal.\"\n",
    "Clonal Selection Algorithm (CSA)\tClassification and optimization ‚Äì based on cloning and mutating best solutions.\n",
    "Immune Network Models\tModels interaction between detectors for self-regulation.\n",
    "Dendritic Cell Algorithm\tUsed in real-time anomaly detection systems (e.g., intrusion detection).\n",
    "\n",
    "üß† Where AIS Is Used\n",
    "Network security (e.g., intrusion detection systems)\n",
    "\n",
    "Medical diagnosis\n",
    "\n",
    "Pattern recognition and classification\n",
    "\n",
    "Fault detection in systems\n",
    "\n",
    "Spam detection\n",
    "\n",
    "Robotics and control systems'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8982e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clonal Selection AIS Accuracy: 0.45\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae6a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322736d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
